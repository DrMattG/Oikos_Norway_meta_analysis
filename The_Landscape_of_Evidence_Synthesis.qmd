---
title: "The Landscape of Evidence Synthesis"
author: Matthew Grainger
email: matthew.grainger@nina.no
format:
  revealjs:
    slide-number: true
    show-slide-number: all
theme: sky
editor: visual
---

## About me

-   Researcher at NINA

-   20+ years of ecological research (10+ years of Evidence synthesis)

-   Co-lead ESHackathon

-   CEE board member

-   Juno Evidence Alliance ["Evidence Synthesis Expert"]{style="color:darkred;"}

-   The Scoping/mapping reviews and EGMs Reviews Methodology Group - Campbell

## What is Evidence Synthesis?

-   Evidence synthesis is the process of gathering, combining, and interpreting research from multiple studies to draw broader conclusions.

- In ecology, we are often tasked with making sense of diverse studies on similar topics, like the effects of land use on species. Evidence synthesis allows us to combine results and make decisions based on the bigger picture.

## Why cant we rely on single studies?

::: {.fragment fragment-index=1}

:::

::: {.fragment fragment-index=1}
-   Single studies can be misleading or misinterpreted.
-   Single studies can be biased, poorly designed, or limited in scope.
-   They may not represent the full range of conditions or species.
-   They can be influenced by publication bias
-   They may not be replicable or generalisable to other contexts.
-   They may not be transparent in their methods or data
:::

## Conflicting results

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: conflicts

library(tidyverse)
library(plotly)
set.seed(42)

# Simulating Biodiversity (Species Richness)
biodiversity <- seq(1, 100, by=1)

# Simulating Different Relationships
data <- data.frame(
  biodiversity = biodiversity,
  
  # 1. Positive Relationship (Tilman et al. 1997)
  productivity_positive = biodiversity * 0.5 + rnorm(length(biodiversity), 0, 5),
  
  # 2. Negative Relationship (Garnier et al. 2004)
  productivity_negative = 100 - biodiversity * 0.5 + rnorm(length(biodiversity), 0, 5),
  
  # 3. Hump-Shaped Relationship (Mittelbach et al. 2001)
  productivity_hump = -0.02 * (biodiversity - 50)^2 + 60 + rnorm(length(biodiversity), 0, 5),
  
  # 4. No Relationship (Wardle et al. 2000)
  productivity_random = runif(length(biodiversity), 20, 80)
)

# Transforming Data for Faceted Plot
plot_data <- data |> 
  pivot_longer(cols = starts_with("productivity"), 
               names_to = "Relationship", 
               values_to = "Productivity") |> 
  mutate(Relationship = case_when(
    Relationship == "productivity_positive" ~ "Positive",
    Relationship == "productivity_negative" ~ "Negative",
    Relationship == "productivity_hump" ~ "Hump-Shaped",
    Relationship == "productivity_random" ~ "No Relationship"
  ))

# Adding Example References
references <- data.frame(
  Relationship = c("Positive", "Negative", "Hump-Shaped", "No Relationship"),
  ref_text = c(
    "Tilman et al. 1997 (Science)",  # Positive Relationship
    "Garnier et al. 2004 (Ecology Letters)",  # Negative Relationship
    "Mittelbach et al. 2001 (Ecology)",  # Hump-Shaped Relationship
    "Wardle et al. 2000 (Oikos)"  # No Relationship
  ),
  x_pos = c(20, 40, 50, 50),  # Approximate x-positions for text placement
  y_pos = c(90, 90, 90, 75)  # Approximate y-positions for text placement
)

# Plotting the Relationships with References
ggplot(plot_data, aes(x = biodiversity, y = Productivity)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  facet_wrap(~ Relationship, scales = "free") +
  geom_text(data = references, aes(x = x_pos, y = y_pos, label = ref_text), inherit.aes = FALSE, size = 4, hjust = 0) +
  labs(title = "Biodiversity-Productivity Relationships",
       x = "Biodiversity (Species Richness)",
       y = "Productivity") +
  theme_minimal()

```

## Small studies

-   [Small studies have a higher probability of false-positives]{style="color:darkred;"}

```{r}
#| echo: false
#| warning: false
#| message: false
# Load necessary libraries
library(pwr)

# Define sample sizes
sample_sizes <- seq(5, 200, by=5)

# Calculate power for two different effect sizes
effect_sizes <- c(0.5, 0.2)  # Moderate (0.5) and small (0.2) effect sizes

power_data <- data.frame(
  SampleSize = rep(sample_sizes, times = 2),
  Power = c(
    sapply(sample_sizes, function(n) pwr.t.test(n = n, d = 0.5, sig.level = 0.05, type = "two.sample")$power),
    sapply(sample_sizes, function(n) pwr.t.test(n = n, d = 0.2, sig.level = 0.05, type = "two.sample")$power)
  ),
  EffectSize = rep(c("0.5 (Moderate)", "0.2 (Small)"), each = length(sample_sizes))
)

# Plot using ggplot2
ggplot(power_data, aes(x = SampleSize, y = Power, color = EffectSize)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  labs(
    title = "Impact of Sample Size on Statistical Power",
    x = "Sample Size",
    y = "Power",
    color = "Effect Size"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("blue", "orange")) +
  theme(legend.position = "bottom")

```


## Too many studies

-   [\> 1.5 million papers published each year]{style="color:darkred;"}

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: load_plot_pub_data

data=readRDS("data/publications_data.RDS")
data<-data |> 
   mutate(across(everything(), ~ gsub(",", ".", .))) |> 
  mutate(across(everything(), as.numeric))

p<-data |>
  ggplot(aes(x=year, y=npub_DIM))+ #totpub_DIM)) +
  geom_col(stat="identity", col="darkred") +
  #geom_point(aes(x=year, y=totpub_DIM), color="red") +
  #geom_smooth(method="lm", se=FALSE) +
  labs(title="Number of publications per year",
       x="Year",
       y="Number of publications")+
  theme_classic()
p  


```



# Types of Evidence Synthesis

## Essential steps in evidence synthesis
![](images/clipboard-3014003817.png)


#  [The Review family]{style="color:darkred;"}
 
## Narrative Review

- A summary of studies, but typically lacks formal methods for study selection or quality assessment.

- Good for broad overviews but less reliable in terms of conclusions.

## Systematic Review

- Uses strict, [predefined]{style=color"darkred"} methods to select studies and assess their quality.

- A systematic review might ask, 'What is the impact of invasive species on native plant communities?' and follows a clear protocol to identify, evaluate, and synthesize the studies.

## Meta-Analysis

- A subset of systematic reviews, but with a statistical approach to combine effect sizes from different studies.

- Meta-analysis quantifies the strength of an effect, such as the average impact of a particular conservation practice on biodiversity, and tests if it's statistically significant.

[You can have a systematic review without a meta-analysis but not a meta-analysis without a systematic review]{style="color:darkred;"}

## Rapid Review

- A streamlined review process used to synthesise evidence quickly, often for urgent policy or management decisions.

- Rapid reviews might be used in fast-moving situations, like evaluating the effectiveness of a new conservation policy in response to a crisis.

[There is no accepted definition of a Rapid Review and we do not often know which components we should cut and then impacts of that]{style="color:darkred;"}

## Living Review

- An ongoing review that is continuously updated as new studies are published.

- Living reviews are useful in rapidly evolving fields, such as climate change, where new evidence is constantly emerging.

## Umbrella Review
- A review of existing systematic reviews, providing a high-level overview of evidence across multiple topics.

- Umbrella reviews can help us understand the broader context of a specific issue, like the overall effectiveness of different conservation strategies across various ecosystems.

- For example, an umbrella review could summarise the findings of multiple systematic reviews on the effects of habitat restoration on biodiversity.

#  [Mapping family]{style="color:darkred;"}

## Systematic Map

- A mapping process that categorises existing research but does not quantitatively synthesise results.

- If we were interested in the global research on climate change effects on bird populations, a systematic map could help us identify research gaps and trends.

## Scoping Review

- A broader review that identifies the extent of research in a particular field or topic, often used to inform future research agendas.

- A scoping review could help us understand how much research exists on the impact of urbanization on amphibian populations.

## Evidence Gap Map (EGM)

- A visual representation of research gaps in a specific area, showing where studies exist and where more research is needed.

- EGMs can help policymakers and researchers identify areas where evidence is lacking, such as the effects of habitat restoration on pollinator populations.


# Why Methodological Rigor Matters

## Different synthesis methods provide varying levels of confidence and transparency

![](images/Pyramid.png)

## 

[![Mupepele, et al. (2016), Ecol Appl, 26: 1295-1301. ](images/Pyramid2.png.jpg)](https://doi.org/10.1890/15-0595)

## Different types of primary evidence

[![Christie, et al. 2019. J Appl Ecol.; 56: 2742–2754. https://doi.org/10.1111/1365-2664.13499](images/clipboard-1547049060.png){width="506"}](https://doi.org/10.1111/1365-2664.13499)

## 

[![Performance of designs](images/clipboard-3628596984.png){width="411"}](https://doi.org/10.1111/1365-2664.14153)


## Common pitfalls 

- Without proper methods to assess study quality and bias, we might miss crucial information that could change the overall interpretation of the evidence

- Publication bias can skew results, as studies with positive findings are more likely to be published.

- Small studies can lead to false positives, as they may not have enough power to detect true effects.



## Recommended literature {.smaller}

[Collaboration for Environmental Evidence, 2018. Guidelines and Standards for Evidence synthesis in Environmental Management. Version 5.0](https://environmentalevidence.org/information-for-authors/table-of-contents-page)

[Cooke et al., 2017. How experimental biology and ecology can support evidence-based decision-making in conservation: avoiding pitfalls and enabling application, Cons Phy, 5(1)](https://doi.org/10.1093/conphys/cox043)

[Foo, et al. 2021. A practical guide to question formation, systematic searching and study screening for literature reviews in ecology and evolution. MEE, 12, 1705–1720.](https://doi.org/10.1111/2041-210X.13654)

[Haddaway et al., 2020. Eight problems with literature reviews and how to fix them. NEE, 4(12), pp.1582-1589.](https://doi.org/10.1038/s41559-020-01295-x)

[James et al. 2016. A methodology for systematic mapping in environmental sciences. Env Evi, 5](https://doi.org/10.1186/s13750-016-0059-6)

[Stewart. 2010. Meta-analysis in applied ecology. Biol. Lett.678–81](http://doi.org/10.1098/rsbl.2009.0546)

[Sutherland et al. 2004. The need for evidence-based conservation. TEE, 19(6), pp.305-308.](http://doi.org/10.1016/j.tree.2004.03.018)
